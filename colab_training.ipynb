{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üß¨ Geometry-Complete Equivariant Diffusion Model\n",
        "## De Novo Drug Design Training Notebook\n",
        "\n",
        "**Requirements:** GPU Runtime (T4), ~50GB disk for real data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 1: Check GPU"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU! Runtime > Change runtime type > GPU\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 2: Install Dependencies"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-geometric rdkit scipy numpy pyyaml tqdm wandb\n",
        "from rdkit import Chem\n",
        "print(\"‚úÖ All dependencies installed\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 3: Clone Repository"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nethrananda21/geom_diffusion.git\n",
        "%cd geom_diffusion\n",
        "!git pull origin master"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 4: Download CrossDocked2020 Dataset (~50GB)\n",
        "‚ö†Ô∏è Skip this cell to use synthetic data for quick testing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CrossDocked2020 (takes ~30 min)\n",
        "!wget --no-check-certificate -q --show-progress http://bits.csb.pitt.edu/files/crossdock2020/CrossDocked2020_v1.3.tgz\n",
        "\n",
        "# Extract\n",
        "!mkdir -p data\n",
        "!tar -xzf CrossDocked2020_v1.3.tgz -C ./data/\n",
        "print(\"‚úÖ Dataset extracted\")\n",
        "\n",
        "# Clean up archive to save space\n",
        "!rm CrossDocked2020_v1.3.tgz"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 5: Preprocess Dataset"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess: creates train_data.pkl and val_data.pkl\n",
        "!python preprocess_crossdocked.py \\\n",
        "    --data_dir ./data/CrossDocked2020 \\\n",
        "    --output_dir ./data/crossdocked \\\n",
        "    --config configs/debug_t4.yaml\n",
        "\n",
        "print(\"\\n‚úÖ Preprocessing complete\")\n",
        "!ls -la data/crossdocked/"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 6: ‚ö†Ô∏è DELETE OLD CACHE (IMPORTANT!)"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# CRITICAL: Delete old synthetic cache to use real data\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "cache_dir = Path('data/cache')\n",
        "if cache_dir.exists():\n",
        "    shutil.rmtree(cache_dir)\n",
        "    print(\"üóëÔ∏è Deleted old cache\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No cache to delete\")\n",
        "\n",
        "# Verify real data exists\n",
        "train_pkl = Path('data/crossdocked/train_data.pkl')\n",
        "val_pkl = Path('data/crossdocked/val_data.pkl')\n",
        "\n",
        "if train_pkl.exists() and val_pkl.exists():\n",
        "    print(f\"‚úÖ Real data ready:\")\n",
        "    print(f\"   - {train_pkl} ({train_pkl.stat().st_size / 1e6:.1f} MB)\")\n",
        "    print(f\"   - {val_pkl} ({val_pkl.stat().st_size / 1e6:.1f} MB)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Real data NOT found - will use synthetic\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 7: Configure Training"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open('configs/debug_t4.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Adjust for Colab\n",
        "config['training']['max_epochs'] = 10  # Quick test\n",
        "config['hardware']['num_workers'] = 2  # Colab limit\n",
        "\n",
        "with open('configs/debug_t4.yaml', 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(f\"‚úÖ Config: batch_size={config['training']['batch_size']}, epochs={config['training']['max_epochs']}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 8: Start Training üöÄ"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# Watch the logs - should say \"Loading preprocessed data\" NOT \"SYNTHETIC\"\n",
        "!python train.py --config configs/debug_t4.yaml --checkpoint_dir ./checkpoints"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 9: Resume Training (If Interrupted)"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to resume from checkpoint\n",
        "# !python train.py --config configs/debug_t4.yaml --resume ./checkpoints/best_model.pt"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## Cell 10: Download Trained Model"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "ckpt = Path('checkpoints/best_model.pt')\n",
        "if ckpt.exists():\n",
        "    files.download(str(ckpt))\n",
        "    print(\"‚úÖ Model downloaded\")\n",
        "else:\n",
        "    print(\"‚ùå No checkpoint yet\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
